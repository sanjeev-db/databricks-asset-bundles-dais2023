resources:

  pipelines:
    # DLT pipeline..
    source2_medium_metrics_pipeline:
      name: "[${bundle.environment}] Source2 FE Medium Metrics Pipeline - Volvo"
      target: "source2_medium_post_report_${bundle.environment}"
      libraries:
        - file:
            path: /home/runner/work/databricks-asset-bundles-dais2023/databricks-asset-bundles-dais2023/source_2/ingest.py
        - file:
            path: /home/runner/work/databricks-asset-bundles-dais2023/databricks-asset-bundles-dais2023/source_2/get_metrics.py
      channel: preview
      configuration:
        "bundle.file_path": "/Workspace/${workspace.file_path}"

  jobs:
    # A two-task Databricks Workflow - dlt + notebook report
    source2_fe_medium_metrics:
      name: "[${bundle.environment}] Source2 Metrics for FE Medium Posts"
      tasks:
        - task_key: source2_dlt_medium_pipeline
          pipeline_task:
            pipeline_id: ${resources.pipelines.source2_medium_metrics_pipeline.id}
        - task_key: "${bundle.environment}_source2_medium_notebook_report"
          depends_on:
            - task_key: source2_dlt_medium_pipeline
          notebook_task:
            base_parameters:
              dbname: "source2_medium_post_report_${bundle.environment}"
            notebook_path: /home/runner/work/databricks-asset-bundles-dais2023/databricks-asset-bundles-dais2023/source_2/fe_medium_report.py
          new_cluster:
            spark_version: 13.1.x-scala2.12
            num_workers: 1
            node_type_id: Standard_DS3_v2      